{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e908551d-b9f3-431f-9e92-a71a72d4467c",
   "metadata": {},
   "source": [
    "# **Step 1 : Custom / Pre-Trained HF Models: Packaging, Compressing, and Uploading to S3 for SageMaker Inference**\n",
    "\n",
    "\t•   Select and download a custom/pre-trained model from Hugging Face.\n",
    "\t•   Organize the model files into the directory structure required by SageMaker.\n",
    "\t•   Package the model directory into a .tar.gz file for SageMaker compatibility.\n",
    "\t•   Upload the tarball to your Amazon S3 bucket for use in SageMaker model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fa685cf-8f76-4eb9-aa3a-488d9cd864fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.57.3)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.21.0+cpu)\n",
      "Requirement already satisfied: torchaudio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu \n",
    "# cpu or cu121 (Replace cu121 with your CUDA version (check via !nvidia-smi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f63a0b1-e4bf-4d35-afdb-9908e26a7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import subprocess\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker import get_execution_role\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8499cc8-5855-4612-881f-08ae035f9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Create Boto Clients\n",
    "# -------------------------------\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70575c36-9a3e-4055-8455-d280dd327c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "\n",
    "hf_model_name = \"<hf_model_repo>\"   # Hugging Face Model Repo ID\n",
    "s3_bucket = \"<bucket_name>\"  # S3 Bucket\n",
    "tar_file_path = \"model.tar.gz\"\n",
    "s3_key = os.path.basename(tar_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea09cd08-0874-4903-9d16-7131d15953fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea9a6a226e34b168a90e2065e9265a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/634 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfd29625d894a24939ce8aad74f1b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309fb814dcb64710a01ad3a60be276a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0d548baf2444c094888493ce0744dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe0690f6954eab89dfb9ed89130dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5aaec42ff1e418bbfe45d76e22f335d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Hugging Face Model 'omkarwazulkar/SentimentModel-V1.0' to 'hf_model'\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Download Own Custom Hugging Face Model\n",
    "# ----------------------------\n",
    "\n",
    "model_folder = \"hf_model\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(hf_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_name)\n",
    "\n",
    "model.save_pretrained(model_folder)\n",
    "tokenizer.save_pretrained(model_folder)\n",
    "print(f\"Downloaded Hugging Face Model '{hf_model_name}' to '{model_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdb55f2-3ee4-4b0e-accb-7a3feb20102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./vocab.txt\n",
      "./tokenizer_config.json\n",
      "./config.json\n",
      "./tokenizer.json\n",
      "./model.safetensors\n",
      "./special_tokens_map.json\n",
      "Compressed Model Folder To 'model.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 2: Compress Model Folder To .tar\n",
    "# -----------------------------\n",
    "\n",
    "if os.path.exists(tar_file_path):\n",
    "    os.remove(tar_file_path)\n",
    "\n",
    "subprocess.run(\n",
    "    [\"tar\", \"-czvf\", tar_file_path, \"-C\", model_folder, \".\"],\n",
    "    check=True\n",
    ")\n",
    "print(f\"Compressed Model Folder To '{tar_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacedf1-6fa6-4d59-80fe-54f37d31415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Step 3: Upload .tar To S3\n",
    "# ----------------------------\n",
    "\n",
    "s3_client.upload_file(tar_file_path, s3_bucket, s3_key)\n",
    "print(f\"Uploaded model to s3://{s3_bucket}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1340ce0c-bef3-4c07-9993-b785022c79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Step 4: Output S3 Location\n",
    "# ----------------------------\n",
    "\n",
    "model_data = f\"s3://{s3_bucket}/{s3_key}\"\n",
    "print(f\"Model Data S3 Location: {model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430579a-30d3-4df5-8de8-bc75287fd1d2",
   "metadata": {},
   "source": [
    "# **Step 2 : Building and Publishing the Model Inference Image from GitHub to Amazon ECR**\n",
    "\t\n",
    "    •   Below a link to your GitHub repository: https://github.com/omkarwazulkar/hf-sagemaker-deploy\n",
    "\t•   Use the repository contents to build the Docker image through AWS CodeBuild.\n",
    "\t•   The files include (Dockerfile, buildspec.yml, requirements.txt, and inference.py)\n",
    "\t•   Create an Amazon ECR repository to store the inference image.\n",
    "\t•   Build the Docker image in CodeBuild and push the final image to the ECR repository.\n",
    "\t•   Ensure the built image includes all required components: \n",
    "            the inference handler script, \n",
    "            model loading logic, dependencies, \n",
    "            and runtime environment needed for SageMaker inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2595e1-ce73-4fe9-9506-0d871b0058d1",
   "metadata": {},
   "source": [
    "# **Step 3 : Configuring SageMaker, Deploying the Model, and Running Inference**\n",
    "\n",
    "\t•   Set up the required SageMaker session, execution role, and configuration parameters.\n",
    "\t•   Define the SageMaker Model using the ECR-hosted inference image and the S3 model artifact.\n",
    "\t•   Deploy the model to a SageMaker endpoint with the desired instance type and configuration.\n",
    "\t•   Create a Predictor object and prepare the inference payload.\n",
    "\t•   Send the payload to the endpoint and retrieve the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d18b42-7b73-4aa1-921c-e838f671858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "\n",
    "AWS_REGION = \"region\"\n",
    "ECR_IMAGE_URI = \"************.dkr.ecr.us-east-1.amazonaws.com/<your_repo_name>:latest\"\n",
    "MODEL_S3_URI = \"s3://<bucket-name>/model.tar.gz\"\n",
    "ENDPOINT_NAME = \"sentiment-classification-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e56422a-5bf4-43d5-adf4-b12682ad7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# SageMaker Session & Role\n",
    "# -------------------------------\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2dd659c-fe1c-4079-9c0c-94fb56852af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define SageMaker Model\n",
    "# -------------------------------\n",
    "\n",
    "model = Model(\n",
    "    image_uri=ECR_IMAGE_URI,\n",
    "    model_data=MODEL_S3_URI,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    env={\n",
    "        'SAGEMAKER_CONTAINER_LOG_LEVEL': '30',\n",
    "        'SAGEMAKER_ENABLE_CLOUDWATCH_LOGGING': 'true'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ae3c88-ee3a-47f8-bac3-36dc0781485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!Endpoint 'sentiment-classification-endpoint' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Deploy Endpoint\n",
    "# -------------------------------\n",
    "\n",
    "try:\n",
    "    predictor = model.deploy(\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        initial_instance_count=1,\n",
    "        endpoint_name=ENDPOINT_NAME\n",
    "    )\n",
    "    print(f\"Endpoint '{ENDPOINT_NAME}' created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to deploy endpoint: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d477a228-9fd8-48ef-804f-277bd367c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define Predictor\n",
    "# -------------------------------\n",
    "\n",
    "predictor = Predictor(endpoint_name=ENDPOINT_NAME, sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6167a7fc-586f-4655-9dd4-ae0a44f06104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define Request Payload\n",
    "# -------------------------------\n",
    "\n",
    "request_body = {\n",
    "    \"text\": [\n",
    "        \"I loved this movie!\",\n",
    "        \"This was awful.\",\n",
    "        \"Amazing storyline and acting.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebc123d6-5893-4317-8e1e-65f6a469c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Send Request To SageMaker Endpoint\n",
    "# -------------------------------\n",
    "\n",
    "response = predictor.predict(\n",
    "    json.dumps(request_body),\n",
    "    initial_args={'ContentType': 'application/json'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3bfd609-98a7-4468-9b6e-0d6719829c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Decode Bytes -> String, Then Parse JSON\n",
    "# -------------------------------\n",
    "\n",
    "prediction = json.loads(response.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "110836dc-a1ab-49e5-9652-5fbde839d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['Positive', 'Negative', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Map Numeric Predictions To Labels\n",
    "# -------------------------------\n",
    "\n",
    "label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "predicted_labels = [label_map[p] for p in prediction['predictions']]\n",
    "print(\"Predictions:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e0e23-0445-462f-8e24-a782587cc886",
   "metadata": {},
   "source": [
    "# **Step 4 : Cleaning Up SageMaker Resources**\n",
    "\n",
    "\t•   Delete the SageMaker endpoint to stop ongoing usage and avoid charges.\n",
    "\t•   Remove the associated endpoint configuration from SageMaker.\n",
    "\t•   Delete the SageMaker model to complete the cleanup process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbada862-d780-4fa2-ac70-60c1bd840ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted endpoint, config, and model: sentiment-classification-endpoint\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Get Latest Endpoint\n",
    "# -------------------------------\n",
    "\n",
    "endpoints = sm.list_endpoints(MaxResults=1)[\"Endpoints\"]\n",
    "if endpoints:\n",
    "    endpoint_name = endpoints[0][\"EndpointName\"]\n",
    "    config_name = sm.describe_endpoint(EndpointName=endpoint_name)[\"EndpointConfigName\"]\n",
    "    model_name = sm.describe_endpoint_config(EndpointConfigName=config_name)[\"ProductionVariants\"][0][\"ModelName\"]\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Delete Endpoint, Config, & Model\n",
    "    # -------------------------------\n",
    "\n",
    "    sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "    sm.delete_endpoint_config(EndpointConfigName=config_name)\n",
    "    sm.delete_model(ModelName=model_name)\n",
    "    print(f\"Deleted endpoint, config, and model: {endpoint_name}\")\n",
    "else:\n",
    "    print(\"No endpoints found to delete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
